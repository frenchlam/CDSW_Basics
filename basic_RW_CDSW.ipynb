{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading / Writing files from HDFS in CDSW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1 : Copy files files locally and work from there\n",
    "**Applicable to:** ***\"small and medium\"*** dataset that can be easily managed/processed locally. <br>\n",
    "**NOTE:** To be used in the context of **sensitive data and/or data that requiere strong governance** as it creates a break in the data chain of custody / security. <br> \n",
    "This is not a best practice in terms of Data Management/Governance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy data FROM HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete file if exits \n",
    "!rm -f /home/cdsw/airlines/airports/airports.csv\n",
    "## get file from HDFS\n",
    "!hdfs dfs -get airlines/airports/airports.csv /home/cdsw/airlines/airports/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read from pandas\n",
    "import pandas as pd\n",
    "airlines_pd_df = pd.read_csv(\"/home/cdsw/airlines/airports/airports.csv\",\n",
    "    sep=',', delimiter=None, header='infer')\n",
    "\n",
    "airlines_pd_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy data TO HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### write data to local file system \n",
    "airlines_pd_df.to_csv(\"/home/cdsw/airlines/airports/airport.zip\", sep=',', header=True, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### push to HDFS\n",
    "!hdfs dfs -copyFromLocal -f /home/cdsw/airlines/airports/airports.zip /tmp/\n",
    "!rm -f /home/cdsw/airlines/airports/airport.zip\n",
    "!hdfs dfs -ls /tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2 (recommended) using spark\n",
    "**Applicable to:**  All datasets and large ones in particular <br> \n",
    "Using spark, allows us to use the data without having to copy first. It's much cleaner in terms of chain of custody <br>\n",
    "**NOTE:** For large dataset, it also allows us to do filtering, pre-processing and filtering in a distributed manner which is much more efficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Get a feel for what the data looks like\n",
    "Read the data using the console <br>\n",
    "**NOTE:** using `-text` rather than `-cat` allows reading from compressed files (zip,gz,bz2,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: log4j.properties is not found. HADOOP_CONF_DIR may be incomplete.\n",
      "\"iata\",\"airport\",\"city\",\"state\",\"country\",\"lat\",\"long\"\n",
      "\"00M\",\"Thigpen \",\"Bay Springs\",\"MS\",\"USA\",31.95376472,-89.23450472\n",
      "\"00R\",\"Livingston Municipal\",\"Livingston\",\"TX\",\"USA\",30.68586111,-95.01792778\n",
      "\"00V\",\"Meadow Lake\",\"Colorado Springs\",\"CO\",\"USA\",38.94574889,-104.5698933\n",
      "\"01G\",\"Perry-Warsaw\",\"Perry\",\"NY\",\"USA\",42.74134667,-78.05208056\n",
      "text: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -text airlines/airports/airports.csv | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading data from HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the spark session\n",
    "Custom session configuration can be defined either in the session parameters as below OR\n",
    "inside a `spark-defaults.conf` file stored at the root of the project (in which case the configs become project wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .master(\"yarn\")\\\n",
    "    .appName(\"Airline\")\\\n",
    "    .config(\"spark.executor.memory\",\"2g\")\\\n",
    "    .config(\"spark.executor.cores\",\"2\")\\\n",
    "    .config(\"spark.driver.memory\",\"2g\")\\\n",
    "    .config(\"spark.executor.instances\",\"2\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://spark-9pv18nxbfhto429c.mlamairesse-training-4.vpc.cloudera.com\" target=\"_blank\" >Spark UI</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding a link to the Spark UI for demo purposes\n",
    "from IPython.core.display import HTML\n",
    "import os\n",
    "HTML('<a href=\"http://spark-{}.{}\" target=\"_blank\" >Spark UI</a>'.\\\n",
    "     format(os.getenv(\"CDSW_ENGINE_ID\"),os.getenv(\"CDSW_DOMAIN\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read the Data - csv file stored on HDFS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- iata: string (nullable = true)\n",
      " |-- airport: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path='airlines/airports/airports.csv' #HDFS location\n",
    "\n",
    "airports_df = spark.read.csv(\n",
    "    path=path,\n",
    "    header=True,\n",
    "    sep=',',\n",
    "    inferSchema=True,\n",
    "    nullValue=None\n",
    ")\n",
    "airports_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : in the above example, I'm infering the schema from the file. <br>\n",
    "It's actually good practice to set the schema to prevent erroneous type casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+----------------+-----+-------+-----------+------------+\n",
      "|iata|             airport|            city|state|country|        lat|        long|\n",
      "+----+--------------------+----------------+-----+-------+-----------+------------+\n",
      "| 00M|            Thigpen |     Bay Springs|   MS|    USA|31.95376472|-89.23450472|\n",
      "| 00R|Livingston Municipal|      Livingston|   TX|    USA|30.68586111|-95.01792778|\n",
      "| 00V|         Meadow Lake|Colorado Springs|   CO|    USA|38.94574889|-104.5698933|\n",
      "| 01G|        Perry-Warsaw|           Perry|   NY|    USA|42.74134667|-78.05208056|\n",
      "| 01J|    Hilliard Airpark|        Hilliard|   FL|    USA| 30.6880125|-81.90594389|\n",
      "+----+--------------------+----------------+-----+-------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "path='airlines/airports/airports.csv' #HDFS location\n",
    "schema = StructType([StructField(\"iata\", StringType(), True),\n",
    "                     StructField(\"airport\", StringType(), True),\n",
    "                     StructField(\"city\", StringType(), True),\n",
    "                     StructField(\"state\", StringType(), True),\n",
    "                     StructField(\"country\", StringType(), True),\n",
    "                     StructField(\"lat\",  DoubleType(), True),\n",
    "                     StructField(\"long\",  DoubleType(), True)\n",
    "                    ])\n",
    "\n",
    "airports_df = spark.read.csv(\n",
    "    path=path,\n",
    "    schema=schema,\n",
    "    header=True,\n",
    "    sep=',',\n",
    "    nullValue=None\n",
    ").cache()\n",
    "airports_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Transform data to Pandas Dataframe\n",
    "Once converted **ALL DATA will be brought locally** and distributed processing ends <br>\n",
    "* Good for small to medium datasets <br>\n",
    "* When working with large datasets, the **data should be sampled** before bringing it locally\n",
    "\n",
    "> **Good Practice**:  Spark context should be stopped `spark.stop()` to release cluster ressources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3376 entries, 0 to 3375\n",
      "Data columns (total 7 columns):\n",
      "iata       3376 non-null object\n",
      "airport    3376 non-null object\n",
      "city       3376 non-null object\n",
      "state      3376 non-null object\n",
      "country    3376 non-null object\n",
      "lat        3376 non-null float64\n",
      "long       3376 non-null float64\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 184.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#without sampling\n",
    "import pandas \n",
    "airport_pandas_df = airports_df.toPandas()\n",
    "airport_pandas_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1111 entries, 0 to 1110\n",
      "Data columns (total 7 columns):\n",
      "iata       1111 non-null object\n",
      "airport    1111 non-null object\n",
      "city       1111 non-null object\n",
      "state      1111 non-null object\n",
      "country    1111 non-null object\n",
      "lat        1111 non-null float64\n",
      "long       1111 non-null float64\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 60.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#with sampling\n",
    "sample_pandas_df = airports_df.sample(1/3,seed=30).toPandas()\n",
    "sample_pandas_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write data to HDFS/HIVE - Using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iata</th>\n",
       "      <th>airport</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>ADK</td>\n",
       "      <td>Adak</td>\n",
       "      <td>Adak</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>51.877964</td>\n",
       "      <td>-176.646031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>AKK</td>\n",
       "      <td>Akhiok</td>\n",
       "      <td>Akhiok</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>56.938691</td>\n",
       "      <td>-154.182556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363</th>\n",
       "      <td>Z13</td>\n",
       "      <td>Akiachak</td>\n",
       "      <td>Akiachak</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>60.904532</td>\n",
       "      <td>-161.420910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>AKI</td>\n",
       "      <td>Akiak</td>\n",
       "      <td>Akiak</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>60.904812</td>\n",
       "      <td>-161.227019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>KQA</td>\n",
       "      <td>Akutan SPB</td>\n",
       "      <td>Akutan</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>54.132467</td>\n",
       "      <td>-165.785311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iata     airport      city state country        lat        long\n",
       "776   ADK        Adak      Adak    AK     USA  51.877964 -176.646031\n",
       "818   AKK      Akhiok    Akhiok    AK     USA  56.938691 -154.182556\n",
       "3363  Z13    Akiachak  Akiachak    AK     USA  60.904532 -161.420910\n",
       "817   AKI       Akiak     Akiak    AK     USA  60.904812 -161.227019\n",
       "1994  KQA  Akutan SPB    Akutan    AK     USA  54.132467 -165.785311"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read from pandas\n",
    "import pandas as pd\n",
    "airlines_pd_df = pd.read_csv(\"/home/cdsw/airlines/airports/airports.csv\",sep=',', delimiter=None, header='infer')\n",
    "airlines_pd_df.sort_values(by=['state','airport'],inplace=True) # ordering to keep same visulisation order \n",
    "airlines_pd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Pandas DataFrame to Spark DataFrame\n",
    "With spark 2.3 and up, integration with Pandas has been reinforced notably with the use of Arrow for faster data transfers [https://issues.apache.org/jira/browse/SPARK-20791]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+--------+-----+-------+-----------+-------------------+\n",
      "|iata|   airport|    city|state|country|        lat|               long|\n",
      "+----+----------+--------+-----+-------+-----------+-------------------+\n",
      "| ADK|      Adak|    Adak|   AK|    USA|51.87796389|       -176.6460306|\n",
      "| AKK|    Akhiok|  Akhiok|   AK|    USA|56.93869083|       -154.1825556|\n",
      "| Z13|  Akiachak|Akiachak|   AK|    USA|60.90453167|-161.42091000000002|\n",
      "| AKI|     Akiak|   Akiak|   AK|    USA|60.90481194|       -161.2270189|\n",
      "| KQA|Akutan SPB|  Akutan|   AK|    USA|54.13246694|       -165.7853111|\n",
      "+----+----------+--------+-----+-------+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (optional) Enable Arrow-based optimised columnar data transfers ; Note : still marked as experimental\n",
    "#spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "\n",
    "#(optional) good practice to define schema to prevent any type casting errors\n",
    "schema = StructType([StructField(\"iata\", StringType(), True),\n",
    "                     StructField(\"airport\", StringType(), True),\n",
    "                     StructField(\"city\", StringType(), True),\n",
    "                     StructField(\"state\", StringType(), True),\n",
    "                     StructField(\"country\", StringType(), True),\n",
    "                     StructField(\"lat\",  DoubleType(), True),\n",
    "                     StructField(\"long\",  DoubleType(), True)\n",
    "                    ])\n",
    "\n",
    "spark_df=spark.createDataFrame(airlines_pd_df,schema=schema)\n",
    "spark_df.orderBy(['state','airport']).show(5) # ordering to keep same visulisation order "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to HDFS - using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df.orderBy(['state','airport']).coalesce(2)\\\n",
    "    .write.parquet('/tmp/airlines/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: log4j.properties is not found. HADOOP_CONF_DIR may be incomplete.\n",
      "Found 3 items\n",
      "-rw-r--r--   2 systest supergroup          0 2019-11-30 10:40 /tmp/airlines/_SUCCESS\n",
      "-rw-r--r--   2 systest supergroup      72995 2019-11-30 10:40 /tmp/airlines/part-00000-62138dbf-fb00-4e34-b5f0-c901a4b13b60-c000.snappy.parquet\n",
      "-rw-r--r--   2 systest supergroup      72510 2019-11-30 10:40 /tmp/airlines/part-00001-62138dbf-fb00-4e34-b5f0-c901a4b13b60-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp/airlines/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Data to Hive - using Spark\n",
    "Spark to hive integration makes it very easy to interact with the cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note : Ordering on write can help optimise reads later on. \n",
    "spark_df.orderBy(['state','airport']).coalesce(2)\\\n",
    "    .write.format('parquet').mode(\"overwrite\")\\\n",
    "    .saveAsTable('default.airports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read Data from Hive \n",
    "All hive configurations are already injected into spark.  Therefore Hive can be called directly using a spark sql context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+-----------+\n",
      "|database|         tableName|isTemporary|\n",
      "+--------+------------------+-----------+\n",
      "| default|          airports|      false|\n",
      "| default|         customers|      false|\n",
      "| default|         sample_07|      false|\n",
      "| default|         sample_08|      false|\n",
      "| default|          web_logs|      false|\n",
      "| default|        wineds_ext|      false|\n",
      "| default|wineds_ext_nolabel|      false|\n",
      "+--------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_statement = '''show tables in default'''\n",
    "spark.sql(sql_statement).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+--------+-----+-------+-----------+-------------------+\n",
      "|iata|   airport|    city|state|country|        lat|               long|\n",
      "+----+----------+--------+-----+-------+-----------+-------------------+\n",
      "| ADK|      Adak|    Adak|   AK|    USA|51.87796389|       -176.6460306|\n",
      "| AKK|    Akhiok|  Akhiok|   AK|    USA|56.93869083|       -154.1825556|\n",
      "| Z13|  Akiachak|Akiachak|   AK|    USA|60.90453167|-161.42091000000002|\n",
      "| AKI|     Akiak|   Akiak|   AK|    USA|60.90481194|       -161.2270189|\n",
      "| KQA|Akutan SPB|  Akutan|   AK|    USA|54.13246694|       -165.7853111|\n",
      "+----+----------+--------+-----+-------+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read table\n",
    "sql_statement = '''select * from default.airports'''\n",
    "airports_df = spark.sql(sql_statement)\n",
    "airports_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iata</th>\n",
       "      <th>airport</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADK</td>\n",
       "      <td>Adak</td>\n",
       "      <td>Adak</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>51.877964</td>\n",
       "      <td>-176.646031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AKK</td>\n",
       "      <td>Akhiok</td>\n",
       "      <td>Akhiok</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>56.938691</td>\n",
       "      <td>-154.182556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z13</td>\n",
       "      <td>Akiachak</td>\n",
       "      <td>Akiachak</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>60.904532</td>\n",
       "      <td>-161.420910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AKI</td>\n",
       "      <td>Akiak</td>\n",
       "      <td>Akiak</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>60.904812</td>\n",
       "      <td>-161.227019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KQA</td>\n",
       "      <td>Akutan SPB</td>\n",
       "      <td>Akutan</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>54.132467</td>\n",
       "      <td>-165.785311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iata     airport      city state country        lat        long\n",
       "0  ADK        Adak      Adak    AK     USA  51.877964 -176.646031\n",
       "1  AKK      Akhiok    Akhiok    AK     USA  56.938691 -154.182556\n",
       "2  Z13    Akiachak  Akiachak    AK     USA  60.904532 -161.420910\n",
       "3  AKI       Akiak     Akiak    AK     USA  60.904812 -161.227019\n",
       "4  KQA  Akutan SPB    Akutan    AK     USA  54.132467 -165.785311"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(OPTIONAL) convert to pandas \n",
    "airlines_pd_df = airports_df.toPandas()\n",
    "airlines_pd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop() ## Release spark ressources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***NOTE:*** Pandas Dataframe is still available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iata</th>\n",
       "      <th>airport</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00M</td>\n",
       "      <td>Thigpen</td>\n",
       "      <td>Bay Springs</td>\n",
       "      <td>MS</td>\n",
       "      <td>USA</td>\n",
       "      <td>31.953765</td>\n",
       "      <td>-89.234505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00R</td>\n",
       "      <td>Livingston Municipal</td>\n",
       "      <td>Livingston</td>\n",
       "      <td>TX</td>\n",
       "      <td>USA</td>\n",
       "      <td>30.685861</td>\n",
       "      <td>-95.017928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00V</td>\n",
       "      <td>Meadow Lake</td>\n",
       "      <td>Colorado Springs</td>\n",
       "      <td>CO</td>\n",
       "      <td>USA</td>\n",
       "      <td>38.945749</td>\n",
       "      <td>-104.569893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01G</td>\n",
       "      <td>Perry-Warsaw</td>\n",
       "      <td>Perry</td>\n",
       "      <td>NY</td>\n",
       "      <td>USA</td>\n",
       "      <td>42.741347</td>\n",
       "      <td>-78.052081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01J</td>\n",
       "      <td>Hilliard Airpark</td>\n",
       "      <td>Hilliard</td>\n",
       "      <td>FL</td>\n",
       "      <td>USA</td>\n",
       "      <td>30.688012</td>\n",
       "      <td>-81.905944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iata               airport              city state country        lat  \\\n",
       "0  00M              Thigpen        Bay Springs    MS     USA  31.953765   \n",
       "1  00R  Livingston Municipal        Livingston    TX     USA  30.685861   \n",
       "2  00V           Meadow Lake  Colorado Springs    CO     USA  38.945749   \n",
       "3  01G          Perry-Warsaw             Perry    NY     USA  42.741347   \n",
       "4  01J      Hilliard Airpark          Hilliard    FL     USA  30.688012   \n",
       "\n",
       "         long  \n",
       "0  -89.234505  \n",
       "1  -95.017928  \n",
       "2 -104.569893  \n",
       "3  -78.052081  \n",
       "4  -81.905944  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_pandas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTION 3 - Read Directly from Pandas ( HIVE ONLY - JDBC ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read using Pandas sql interface (Compatible with pyhive or SQLAlchmy)\n",
    "**NOTE:** Must have know Hive host and port (default 10000) information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airports.iata</th>\n",
       "      <th>airports.airport</th>\n",
       "      <th>airports.city</th>\n",
       "      <th>airports.state</th>\n",
       "      <th>airports.country</th>\n",
       "      <th>airports.lat</th>\n",
       "      <th>airports.long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADK</td>\n",
       "      <td>Adak</td>\n",
       "      <td>Adak</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>51.877964</td>\n",
       "      <td>-176.646031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AKK</td>\n",
       "      <td>Akhiok</td>\n",
       "      <td>Akhiok</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>56.938691</td>\n",
       "      <td>-154.182556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z13</td>\n",
       "      <td>Akiachak</td>\n",
       "      <td>Akiachak</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>60.904532</td>\n",
       "      <td>-161.420910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AKI</td>\n",
       "      <td>Akiak</td>\n",
       "      <td>Akiak</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>60.904812</td>\n",
       "      <td>-161.227019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KQA</td>\n",
       "      <td>Akutan SPB</td>\n",
       "      <td>Akutan</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>54.132467</td>\n",
       "      <td>-165.785311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airports.iata airports.airport airports.city airports.state  \\\n",
       "0           ADK             Adak          Adak             AK   \n",
       "1           AKK           Akhiok        Akhiok             AK   \n",
       "2           Z13         Akiachak      Akiachak             AK   \n",
       "3           AKI            Akiak         Akiak             AK   \n",
       "4           KQA       Akutan SPB        Akutan             AK   \n",
       "\n",
       "  airports.country  airports.lat  airports.long  \n",
       "0              USA     51.877964    -176.646031  \n",
       "1              USA     56.938691    -154.182556  \n",
       "2              USA     60.904532    -161.420910  \n",
       "3              USA     60.904812    -161.227019  \n",
       "4              USA     54.132467    -165.785311  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with pyhive\n",
    "from pyhive import hive\n",
    "import pandas as pd\n",
    "conn=hive.Connection(host='mlamairesse-training-1.vpc.cloudera.com', port=10000, auth='KERBEROS', \n",
    "                     kerberos_service_name='hive')\n",
    "airlines_pd_df = pd.read_sql('select * from default.airports',conn)\n",
    "airlines_pd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iata</th>\n",
       "      <th>airport</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADK</td>\n",
       "      <td>Adak</td>\n",
       "      <td>Adak</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>51.877964</td>\n",
       "      <td>-176.646031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AKK</td>\n",
       "      <td>Akhiok</td>\n",
       "      <td>Akhiok</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>56.938691</td>\n",
       "      <td>-154.182556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Z13</td>\n",
       "      <td>Akiachak</td>\n",
       "      <td>Akiachak</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>60.904532</td>\n",
       "      <td>-161.420910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AKI</td>\n",
       "      <td>Akiak</td>\n",
       "      <td>Akiak</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>60.904812</td>\n",
       "      <td>-161.227019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KQA</td>\n",
       "      <td>Akutan SPB</td>\n",
       "      <td>Akutan</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>54.132467</td>\n",
       "      <td>-165.785311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iata     airport      city state country        lat        long\n",
       "0  ADK        Adak      Adak    AK     USA  51.877964 -176.646031\n",
       "1  AKK      Akhiok    Akhiok    AK     USA  56.938691 -154.182556\n",
       "2  Z13    Akiachak  Akiachak    AK     USA  60.904532 -161.420910\n",
       "3  AKI       Akiak     Akiak    AK     USA  60.904812 -161.227019\n",
       "4  KQA  Akutan SPB    Akutan    AK     USA  54.132467 -165.785311"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with SQLAlchemy\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "conn = create_engine(\"hive://systest@mlamairesse-training-1.vpc.cloudera.com:10000/default\",\n",
    "                     connect_args={'auth': 'KERBEROS','kerberos_service_name': 'hive'})\n",
    "#engine = create_engine(\"hive://<kerberos-username>@<hive-host>:<hive-port>/<db-name>\",connect_args={'auth': 'KERBEROS','kerberos_service_name': 'hive'})\n",
    "airlines_pd_df = pd.read_sql('select * from default.airports',conn)\n",
    "airlines_pd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
